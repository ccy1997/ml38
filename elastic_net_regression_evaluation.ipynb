{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating linear and polynomial regression with elastic net regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as lm\n",
    "import random\n",
    "import DataPrepUtil\n",
    "import Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pandas.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ccy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\users\\ccy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\ccy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "DataPrepUtil.transform_ocean_proximity(housing)\n",
    "Impute.fill_lr_prediction_from_other_column(housing, 'total_rooms')\n",
    "\n",
    "standard = preprocessing.StandardScaler().fit(housing)\n",
    "df = standard.transform(housing)\n",
    "\n",
    "median_house_value_bc, maxlog, interval = stats.boxcox(housing.median_house_value, alpha=0.05)\n",
    "population_bc, maxlog, interval = stats.boxcox(housing.population, alpha=0.05)\n",
    "housing_median_age_bc, maxlog, interval = stats.boxcox(housing.housing_median_age, alpha=0.05)\n",
    "total_rooms_bc, maxlog, interval = stats.boxcox(housing.total_rooms, alpha=0.05)\n",
    "total_bedrooms_bc, maxlog, interval = stats.boxcox(housing.total_bedrooms, alpha=0.05)\n",
    "households_bc, maxlog, interval = stats.boxcox(housing.households, alpha=0.05)\n",
    "median_income_bc, maxlog, interval = stats.boxcox(housing.median_income, alpha=0.05)\n",
    "\n",
    "housing_boxcox = housing.copy()\n",
    "\n",
    "housing_boxcox.drop(columns=['housing_median_age'], inplace=True)\n",
    "housing_boxcox.drop(columns=['total_rooms'], inplace=True)\n",
    "housing_boxcox.drop(columns=['total_bedrooms'], inplace=True)\n",
    "housing_boxcox.drop(columns=['population'], inplace=True)\n",
    "housing_boxcox.drop(columns=['households'], inplace=True)\n",
    "housing_boxcox.drop(columns=['median_income'], inplace=True)\n",
    "housing_boxcox.drop(columns=['median_house_value'], inplace=True)\n",
    "\n",
    "housing_boxcox['housing_median_age'] = housing_median_age_bc\n",
    "housing_boxcox['total_rooms'] = total_rooms_bc\n",
    "housing_boxcox['total_bedrooms'] = total_bedrooms_bc\n",
    "housing_boxcox['population'] = population_bc\n",
    "housing_boxcox['households'] = households_bc\n",
    "housing_boxcox['median_income'] = median_income_bc\n",
    "housing_boxcox['median_house_value'] = median_house_value_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing_boxcox.median_house_value.values.reshape(-1,1)\n",
    "X = housing_boxcox.drop(columns=['median_house_value'], inplace=False).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create polynomial features from the original input features (for polynomial regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 105)\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(housing_boxcox.drop(columns=['median_house_value'], inplace=False).values)\n",
    "print(X_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.sample(range(0,20640),5000)\n",
    "X_test = X[test]\n",
    "X_poly_test = X_poly[test]\n",
    "y_test = y[test]\n",
    "X_train_valid = np.delete(X, test, 0)\n",
    "X_poly_train_valid = np.delete(X_poly, test, 0)\n",
    "y_train_valid = np.delete(y, test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables for holding the optimal models and the corresponding validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChosenLinearModel = None\n",
    "current_score_linear = -1\n",
    "current_paramater_linear = -1\n",
    "\n",
    "ChosenPolyModel = None\n",
    "current_score_poly = -1\n",
    "current_paramater_poly = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of linear regression on different value of regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0.01\n",
      "Average training r2 score: 0.6881225793522856\n",
      "Average validation r2 score: 0.6873224625524761\n",
      "a = 0.03\n",
      "Average training r2 score: 0.6800257797295705\n",
      "Average validation r2 score: 0.6795100973096602\n",
      "a = 0.049999999999999996\n",
      "Average training r2 score: 0.6743401255415954\n",
      "Average validation r2 score: 0.6737976752449859\n",
      "a = 0.06999999999999999\n",
      "Average training r2 score: 0.6675198973577744\n",
      "Average validation r2 score: 0.6666471727749059\n",
      "a = 0.08999999999999998\n",
      "Average training r2 score: 0.6593730002589011\n",
      "Average validation r2 score: 0.6588380561080109\n",
      "a = 0.10999999999999997\n",
      "Average training r2 score: 0.6511796472267556\n",
      "Average validation r2 score: 0.6503098463146763\n",
      "a = 0.12999999999999998\n",
      "Average training r2 score: 0.6426981086520334\n",
      "Average validation r2 score: 0.6417339954806979\n",
      "a = 0.15\n",
      "Average training r2 score: 0.6318938700964627\n",
      "Average validation r2 score: 0.6311352082365342\n",
      "a = 0.16999999999999998\n",
      "Average training r2 score: 0.6225752664018785\n",
      "Average validation r2 score: 0.6217044073592383\n",
      "a = 0.18999999999999997\n",
      "Average training r2 score: 0.6127517020244776\n",
      "Average validation r2 score: 0.6123233944304814\n",
      "Optimal model (linear): a = 0.01\n"
     ]
    }
   ],
   "source": [
    "for a in np.arange(0.01, 0.2, 0.02):\n",
    "    print(\"a = \" + str(a))\n",
    "    \n",
    "    Model = lm.ElasticNet(alpha=a, max_iter=3000, tol=0.13)\n",
    "    \n",
    "    # Have to shuffle the data because it is grouped.\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    total_train_score = 0\n",
    "    total_valid_score = 0\n",
    "    \n",
    "    for train_index, valid_index in kf.split(X_train_valid):\n",
    "        X_train, X_valid = X_train_valid[train_index], X_train_valid[valid_index]\n",
    "        y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
    "        Model.fit(X_train, y_train)\n",
    "        total_train_score += Model.score(X_train, y_train)\n",
    "        total_valid_score += Model.score(X_valid, y_valid)\n",
    "        \n",
    "    avg_train_score = total_train_score / 5\n",
    "    avg_valid_score = total_valid_score / 5\n",
    "    avg_train_valid_score = (avg_train_score + avg_valid_score) / 2\n",
    "    print(\"Average training r2 score: \" + str(avg_train_score))\n",
    "    print(\"Average validation r2 score: \" + str(avg_valid_score))\n",
    "    \n",
    "    if (ChosenLinearModel is None) or (avg_train_valid_score > current_score_linear):\n",
    "        ChosenLinearModel = Model\n",
    "        current_score_linear = avg_train_valid_score\n",
    "        current_paramater_linear = a\n",
    "\n",
    "print(\"Optimal model (linear): a = \" + str(current_paramater_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of polynomial regression on different value of regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0.01\n",
      "Average training r2 score: 0.7406833610278759\n",
      "Average validation r2 score: 0.7376190214612475\n",
      "a = 0.03\n",
      "Average training r2 score: 0.7384987408266317\n",
      "Average validation r2 score: 0.7350819239674405\n",
      "a = 0.049999999999999996\n",
      "Average training r2 score: 0.7357274262616826\n",
      "Average validation r2 score: 0.7328390275076738\n",
      "a = 0.06999999999999999\n",
      "Average training r2 score: 0.7336404154486871\n",
      "Average validation r2 score: 0.7311215571066219\n",
      "a = 0.08999999999999998\n",
      "Average training r2 score: 0.7277558990921683\n",
      "Average validation r2 score: 0.7251235322462418\n",
      "a = 0.10999999999999997\n",
      "Average training r2 score: 0.7260841919320792\n",
      "Average validation r2 score: 0.72330276585228\n",
      "a = 0.12999999999999998\n",
      "Average training r2 score: 0.7181357945397442\n",
      "Average validation r2 score: 0.7163262530589753\n",
      "a = 0.15\n",
      "Average training r2 score: 0.7200909557005497\n",
      "Average validation r2 score: 0.7173958710973505\n",
      "a = 0.16999999999999998\n",
      "Average training r2 score: 0.7152670499125772\n",
      "Average validation r2 score: 0.7132411347429441\n",
      "a = 0.18999999999999997\n",
      "Average training r2 score: 0.7143633148990809\n",
      "Average validation r2 score: 0.7125433340571996\n",
      "a = 0.20999999999999996\n",
      "Average training r2 score: 0.7134956404161864\n",
      "Average validation r2 score: 0.7119144856906721\n",
      "a = 0.22999999999999998\n",
      "Average training r2 score: 0.7128595283056942\n",
      "Average validation r2 score: 0.7108702957899528\n",
      "a = 0.24999999999999997\n",
      "Average training r2 score: 0.7125809264823056\n",
      "Average validation r2 score: 0.7102436751946364\n",
      "a = 0.26999999999999996\n",
      "Average training r2 score: 0.7120798259229922\n",
      "Average validation r2 score: 0.7102115998571733\n",
      "a = 0.29\n",
      "Average training r2 score: 0.7116901265359925\n",
      "Average validation r2 score: 0.7101130773093253\n",
      "a = 0.30999999999999994\n",
      "Average training r2 score: 0.7113728634781082\n",
      "Average validation r2 score: 0.7092259615971647\n",
      "a = 0.32999999999999996\n",
      "Average training r2 score: 0.7109910910269132\n",
      "Average validation r2 score: 0.7090112763710236\n",
      "a = 0.35\n",
      "Average training r2 score: 0.7107521351121744\n",
      "Average validation r2 score: 0.7089393909589159\n",
      "a = 0.36999999999999994\n",
      "Average training r2 score: 0.7103559460673348\n",
      "Average validation r2 score: 0.7087395238148646\n",
      "a = 0.38999999999999996\n",
      "Average training r2 score: 0.7100717549228098\n",
      "Average validation r2 score: 0.7082214704197087\n",
      "a = 0.4099999999999999\n",
      "Average training r2 score: 0.7096679089139424\n",
      "Average validation r2 score: 0.7075793401831406\n",
      "a = 0.42999999999999994\n",
      "Average training r2 score: 0.7092958868669946\n",
      "Average validation r2 score: 0.7078224143904099\n",
      "a = 0.44999999999999996\n",
      "Average training r2 score: 0.708867122180225\n",
      "Average validation r2 score: 0.7074397242646702\n",
      "a = 0.4699999999999999\n",
      "Average training r2 score: 0.70842054921459\n",
      "Average validation r2 score: 0.7066387244594979\n",
      "a = 0.48999999999999994\n",
      "Average training r2 score: 0.7081056309550903\n",
      "Average validation r2 score: 0.7066175741211455\n",
      "Optimal model (polynomial): a = 0.01\n"
     ]
    }
   ],
   "source": [
    "for a in np.arange(0.01, 0.5, 0.02):\n",
    "    print(\"a = \" + str(a))\n",
    "    \n",
    "    Model = lm.ElasticNet(alpha=a, max_iter=3000, tol=0.13)\n",
    "    \n",
    "    # Have to shuffle the data because it is grouped.\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    total_train_score = 0\n",
    "    total_valid_score = 0\n",
    "    \n",
    "    for train_index, valid_index in kf.split(X_train_valid):\n",
    "        X_train, X_valid = X_poly_train_valid[train_index], X_poly_train_valid[valid_index]\n",
    "        y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
    "        Model.fit(X_train, y_train)\n",
    "        total_train_score += Model.score(X_train, y_train)\n",
    "        total_valid_score += Model.score(X_valid, y_valid)\n",
    "        \n",
    "    avg_train_score = total_train_score / 5\n",
    "    avg_valid_score = total_valid_score / 5\n",
    "    avg_train_valid_score = (avg_train_score + avg_valid_score) / 2\n",
    "    print(\"Average training r2 score: \" + str(avg_train_score))\n",
    "    print(\"Average validation r2 score: \" + str(avg_valid_score))\n",
    "    \n",
    "    if (ChosenPolyModel is None) or (avg_train_valid_score > current_score_poly):\n",
    "        ChosenPolyModel = Model\n",
    "        current_score_poly = avg_train_valid_score\n",
    "        current_paramater_poly = a\n",
    "\n",
    "print(\"Optimal model (polynomial): a = \" + str(current_paramater_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final performance score of the optimal models evaluated on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of optimal linear model: 0.6885040824911826\n",
      "R2 score of optimal polynomial model: 0.7404239330189452\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 score of optimal linear model: \" + str (ChosenLinearModel.score(X_test, y_test)))\n",
    "print(\"R2 score of optimal polynomial model: \" + str(ChosenPolyModel.score(X_poly_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
